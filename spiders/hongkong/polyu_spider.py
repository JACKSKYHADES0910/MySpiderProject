# -*- coding: utf-8 -*-
"""
é¦™æ¸¯ç†å·¥å¤§å­¦ (PolyU) çˆ¬è™«
ç›®æ ‡ç½‘å€: https://www.polyu.edu.hk/study/pg/taught-postgraduate/find-your-programmes-tpg
"""

import time
from typing import List, Dict
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup
from spiders.base_spider import BaseSpider

class PolyUSpider(BaseSpider):
    def __init__(self, headless: bool = True):
        super().__init__("polyu", headless=headless)
        # self.list_url is automatically derived from config
        self.apply_url = "https://www38.polyu.edu.hk/eAdmission/index.do"

    def run(self) -> List[Dict]:
        print(f"ğŸš€ å¼€å§‹æŠ“å– {self.university_info.get('name', 'PolyU')}...")
        print(f"ğŸ“ åˆ—è¡¨é¡µ: {self.list_url}")
        
        self.driver.get(self.list_url)
        
        # ç­‰å¾…åˆ—è¡¨åŠ è½½
        try:
            WebDriverWait(self.driver, 20).until(
                EC.presence_of_element_located((By.CLASS_NAME, "programmes-items"))
            )
            # ç¨ä½œç­‰å¾…ç¡®ä¿å†…å®¹æ¸²æŸ“
            time.sleep(5)
        except Exception as e:
            print(f"âš ï¸ ç­‰å¾…é¡¹ç›®åˆ—è¡¨åŠ è½½è¶…æ—¶: {e}")
            return []
            
        # è·å–é¡µé¢æºç è¿›è¡Œç¦»çº¿è§£æ
        print("ğŸ“¸ æŠ“å–é¡µé¢å¿«ç…§...")
        html = self.driver.page_source
        soup = BeautifulSoup(html, 'html.parser')
        
        results = []
        
        # æŸ¥æ‰¾æ‰€æœ‰å­¦é™¢åŒºå— (programmes-row)
        # æ¯ä¸ªå­¦é™¢éƒ½æœ‰è‡ªå·±çš„ programmes-row > programmes-items > views-row ç»“æ„
        faculty_blocks = soup.select(".programmes-row")
        print(f"ğŸ“¦ å‘ç° {len(faculty_blocks)} ä¸ªå­¦é™¢åŒºå—")
        
        for faculty_idx, faculty_block in enumerate(faculty_blocks):
            # è·å–å­¦é™¢åç§°ï¼ˆå¯é€‰ï¼Œç”¨äºè°ƒè¯•ï¼‰
            faculty_title_el = faculty_block.select_one(".faculty-title")
            faculty_name = faculty_title_el.get_text(strip=True) if faculty_title_el else f"Faculty {faculty_idx+1}"
            
            # åœ¨è¯¥å­¦é™¢ä¸‹æŸ¥æ‰¾ programmes-items å®¹å™¨
            items_container = faculty_block.select_one(".programmes-items")
            if not items_container:
                continue
                
            # åœ¨è¯¥å®¹å™¨ä¸‹æŸ¥æ‰¾æ‰€æœ‰é¡¹ç›®è¡Œ
            items = items_container.select(".views-row")
            print(f"  ğŸ“š {faculty_name}: {len(items)} ä¸ªé¡¹ç›®")
            
            for item in items:
                try:
                    # æå–é“¾æ¥å…ƒç´ 
                    link_el = item.select_one("a.programme")
                    if not link_el:
                        continue
                        
                    href = link_el.get("href")
                    if not href:
                        continue
                        
                    # å¤„ç†ç›¸å¯¹é“¾æ¥
                    full_link = href
                    if href.startswith("/"):
                        full_link = "https://www.polyu.edu.hk" + href
                    elif not href.startswith("http"):
                        # è¿˜æœ‰å¯èƒ½æ˜¯ç›¸å¯¹è·¯å¾„ä½†æ²¡æœ‰æ–œæ ï¼Œè§†æƒ…å†µè€Œå®šï¼ŒPolyUé€šå¸¸æ˜¯ä»¥/å¼€å¤´
                        full_link = "https://www.polyu.edu.hk/" + href
                    
                    # æå–æ ‡é¢˜
                    title_el = item.select_one(".title")
                    title = title_el.get_text(strip=True) if title_el else ""
                    
                    # æå–å‰¯æ ‡é¢˜ (ä¸­æ–‡å)
                    subtitle_el = item.select_one(".subtitle")
                    subtitle = subtitle_el.get_text(strip=True) if subtitle_el else ""
                    
                    # ç»„åˆåç§°ï¼Œæ–¹ä¾¿è¯†åˆ«
                    full_name = f"{title} {subtitle}".strip()
                    
                    # æå–æˆªæ­¢æ—¥æœŸ
                    deadline = "N/A"
                    deadline_el = item.select_one(".deadline-section")
                    if deadline_el:
                        # ä¼˜å…ˆæŸ¥æ‰¾ Non-Local
                        non_local_div = deadline_el.find("div", string=lambda t: t and "Non-Local" in t)
                        if non_local_div:
                            raw_dl = non_local_div.get_text(strip=True)
                            # æ ¼å¼: "Non-Local Application Deadline: 15 Jan 2026 (Main Round)"
                            # æå–å†’å·åçš„éƒ¨åˆ†
                            if ":" in raw_dl:
                                deadline = raw_dl.split(":", 1)[1].strip()
                            else:
                                deadline = raw_dl
                        else:
                            # å¦‚æœæ²¡æœ‰ Non-Localï¼Œå°è¯• Local
                            local_div = deadline_el.find("div", string=lambda t: t and "Local" in t)
                            if local_div:
                                 raw_dl = local_div.get_text(strip=True)
                                 if ":" in raw_dl:
                                    deadline = raw_dl.split(":", 1)[1].strip()
                                 else:
                                    deadline = raw_dl
                    
                    # ç»„åˆä¸­è‹±æ–‡é¡¹ç›®åç§° (å®˜ç½‘åŸå§‹æ ¼å¼)
                    full_program_name = f"{title} {subtitle}".strip() if subtitle else title
                    
                    # ä½¿ç”¨ BaseSpider çš„æ ‡å‡†æ¨¡æ¿
                    program_data = self.create_result_template(full_program_name, full_link)
                    program_data["é¡¹ç›®deadline"] = deadline
                    program_data["é¡¹ç›®ç”³è¯·é“¾æ¥"] = self.apply_url
                    
                    results.append(program_data)
                    
                except Exception as e:
                    print(f"âš ï¸ è§£ææ¡ç›®å‡ºé”™: {e}")
                    continue
                
        # é¢†å¯¼è¦æ±‚ï¼šåšå£«é¡¹ç›®ä¹Ÿè¦æŠ“å–ï¼Œä¸å†è¿‡æ»¤
        print(f"âœ… æŠ“å–å®Œæˆï¼Œå…± {len(results)} ä¸ªé¡¹ç›®ï¼ˆåŒ…å«åšå£«é¡¹ç›®ï¼‰")
        return results

    def filter_doctor_programmes(self, items: List[Dict]) -> List[Dict]:
        """
        è¿‡æ»¤åšå£« (Doctor/PhD) é¡¹ç›®
        """
        filtered = []
        doctor_keywords = ["Doctor", "PhD", "D.B.A.", "EngD", "Philosophy"]
        
        for item in items:
            # ä½¿ç”¨æ­£ç¡®çš„å­—æ®µå (ä¸­æ–‡)
            name = item.get("é¡¹ç›®åç§°", "")
            cn_name = item.get("å­¦ç”Ÿæ¡ˆä¾‹", "")  # ä¸­æ–‡åå­˜å‚¨åœ¨è¿™é‡Œ
            
            is_doctor = False
            for kw in doctor_keywords:
                if kw in name:
                    is_doctor = True
                    break
            
            # ä¹Ÿå¯ä»¥æ£€æŸ¥ä¸­æ–‡ "åšå£«"
            if "åšå£«" in cn_name:
                is_doctor = True
                
            if not is_doctor:
                filtered.append(item)
            # else:
            #     print(f"ğŸš« è¿‡æ»¤åšå£«é¡¹ç›®: {name}")  # è°ƒè¯•ç”¨
                
        return filtered

if __name__ == "__main__":
    # ç®€å•çš„æµ‹è¯•è¿è¡Œé€»è¾‘
    spider = PolyUSpider(headless=False)
    results = spider.run()
    import json
    print(json.dumps(results, indent=2, ensure_ascii=False))
